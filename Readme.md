# PotentialTalentHunt

An **end-to-end AI-powered talent search and ranking system** built with **FastAPI**, **FAISS**, **Gradio**, and modern MLOps practices. The project demonstrates how to go from **data analysis and experimentation** to a **production-ready ML application** deployed using **Docker** and **AWS ECS**.

The system enables recruiters or analysts to search and rank potential candidates (job profiles / resumes) using semantic vector similarity and configurable ranking logic (including a STAR-style ranking endpoint).

---
Apziva project code: AbTK0iyp4MBSTNLb
---
## ğŸš€ Project Overview

This repository showcases a complete ML application lifecycle:

- ğŸ“Š **Exploratory analysis & modeling** using Jupyter notebooks
- ğŸ§  **Semantic search** with embeddings + FAISS
- ğŸ”Œ **FastAPI backend** for model inference and ranking APIs
- ğŸ–¥ï¸ **Gradio GUI** for interactive user access
- ğŸ³ **Dockerized application** for reproducible builds
- â˜ï¸ **AWS ECS deployment** for scalable, production-grade serving

---

## ğŸš€ Features

- ğŸ” **Semantic Search** over job descriptions / candidate profiles
- ğŸ§  **Vector Embeddings + FAISS Index** for fast similarity search
- â­ **STAR Ranking Endpoint** (extensible ranking logic)
- ğŸ“Š **Notebook-based analysis & experimentation**
- ğŸ–¥ï¸ **Gradio-based GUI** for interactive querying
- ğŸ³ **Dockerized FastAPI app** for deployment
- â˜ï¸ **AWS ECS deployment** enabling an end-to-end ML system

---

## ğŸ§± Tech Stack

- **Python 3.10**
- **FastAPI** â€“ REST API backend
- **FAISS** â€“ Vector similarity search
- **Sentence Transformers / Embeddings**
- **Gradio** â€“ Lightweight web-based GUI
- **Pandas / NumPy** â€“ Data processing
- **Docker** â€“ Containerization
- **AWS ECS** â€“ Cloud deployment
- **Uvicorn** â€“ ASGI server

---

## ğŸ“ Project Structure

```text
PotentialTalentHunt/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                     # FastAPI application (API entry point)
â”‚   â”œâ”€â”€ functions.py                # Core ML logic: FAISS search & ranking
â”‚   â”œâ”€â”€ Dockerfile                  # Docker configuration for deployment
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ gr_gui.py                   # Gradio GUI application
â”‚   â”œâ”€â”€ potentialtalent_V1_2.ipynb  # End-to-end analysis & experimentation
â”‚   â””â”€â”€ experiments.ipynb           # Additional modeling / ranking tests
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw candidate / JD data
â”‚   â”œâ”€â”€ processed/                  # Cleaned / vectorized data
â”‚   â””â”€â”€ index/                      # FAISS index files
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project documentation
â”‚
â””â”€â”€ images/
    â””â”€â”€ screenshots/                # UI / architecture screenshots
```

---

## ğŸ“Š Notebooks

- **`potentialtalent_V1_2.ipynb`**  \
  Contains exploratory data analysis, embedding generation, FAISS indexing, and ranking experiments.

- **`gr_gui.py`**  \
  Implements a **Gradio-based GUI** that connects to the FastAPI backend, allowing users to run semantic searches and view ranked candidates interactively.

- **`expermiments.ipynb`**  \
  Testing FASTAPI endpoints at various stage i.e. locally, docker and on ECS (post deployment)

---

## ğŸ”Œ API Endpoints

### Health Check
```
GET /health
```
Returns API status.

---

### Semantic Search
```
POST /search_jds
```
**Payload:**
```json
{
  "query": "text to search",
  "top_k": 10,
  "threshold": 0.6
}
```

---

### STAR Rank Search
```
POST /star_rank
```
Same payload structure as `/search_jds`, with ranking logic designed to be extended.

---

## ğŸ–¥ï¸ Running the Project Locally

### 1ï¸âƒ£ Create & Activate Environment
```bash
conda create -n tf310 python=3.10
conda activate tf310
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Run FastAPI Backend
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

API docs available at:
```
http://localhost:8000/docs
```

---

### 3ï¸âƒ£ Run Gradio GUI
```bash
python notebooks/gr_gui.py
```

Gradio will launch a local web UI (typically at `http://127.0.0.1:7860`) that communicates with the FastAPI backend.

---

## ğŸ—ï¸ System Architecture

### End-to-End Architecture (Local â†’ Docker â†’ AWS ECS)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Local Machine       â”‚
â”‚                            â”‚
â”‚  Jupyter Notebook          â”‚
â”‚  (analysis & experiments)  â”‚
â”‚        â”‚                   â”‚
â”‚        â–¼                   â”‚
â”‚  Gradio UI (gr_gui.py)     â”‚
â”‚        â”‚  HTTP requests    â”‚
â”‚        â–¼                   â”‚
â”‚  FastAPI Backend           â”‚
â”‚  (FAISS + ML logic)        â”‚
â”‚        â”‚                   â”‚
â”” â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Docker Image
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Docker Container    â”‚
â”‚                            â”‚
â”‚  FastAPI App               â”‚
â”‚  + FAISS Index             â”‚
â”‚                            â”‚
â”” â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Push Image
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Docker Hub          â”‚
â”‚  (Container Registry)      â”‚
â”” â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Deploy
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AWS ECS             â”‚
â”‚  (Fargate / EC2)           â”‚
â”‚                            â”‚
â”‚  FastAPI Service           â”‚
â”‚  Scalable Inference API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This architecture demonstrates how the project transitions from **local experimentation** to a **cloud-deployed, production-ready ML service**.

---

## ğŸ–¥ï¸ Gradio + FastAPI Interaction Flow

```text
User (Browser)
      â”‚
      â–¼
Gradio UI (gr_gui.py)
      â”‚  REST calls
      â–¼
FastAPI Backend (app/main.py)
      â”‚
      â–¼
FAISS Index + Embedding Model
      â”‚
      â–¼
Ranked Candidate Results
```

Gradio acts as a lightweight frontend, while FastAPI serves as the core inference and ranking engine.

---

## ğŸ—ï¸ Architecture

### End-to-End Flow (Local â†’ Docker â†’ AWS ECS)

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Local Dev          â”‚
â”‚  (Notebook / Scripts)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 1) Build embeddings + FAISS index
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FAISS Index + Metadata   â”‚
â”‚ (data/index + processed)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 2) Serve model/search via API
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI Backend       â”‚
â”‚        app/main.py         â”‚
â”‚  /health /search /star_rankâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 3) Containerize
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Docker            â”‚
â”‚  Image: fastapi + faiss    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 4) Push image
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Docker Hub            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 5) Deploy service
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Amazon ECS (Fargate/EC2) â”‚
â”‚  Task/Service + Load Bal.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ 6) User access
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client UI / Consumers    â”‚
â”‚  Gradio UI + other clients â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Gradio + FastAPI Interaction

```text
User (Browser)
   â”‚
   â”‚ HTTP
   â–¼
Gradio UI (notebooks/gr_gui.py)
   â”‚
   â”‚ REST calls (requests)
   â–¼
FastAPI API (app/main.py)
   â”‚
   â”‚ vectorize + search
   â–¼
FAISS Index + Candidate Metadata
   â”‚
   â–¼
Ranked Results (JSON) â†’ Gradio table
```

---

## ğŸ³ Docker & AWS ECS Deployment

- The FastAPI application is containerized using **Docker**
- The Docker image is pushed to **Amazon ECR**
- The image is deployed on **AWS ECS** (Fargate or EC2-backed) behind a load balancer for scalable inference

---

## ğŸš¢ Deployment Guide (ECR â†’ ECS)

Below is a practical, high-level deployment flow for pushing your container to **Amazon ECR** and running it on **Amazon ECS**.

### 1) Prerequisites
- AWS account + IAM permissions for **ECR** and **ECS**
- AWS CLI installed and configured:
  ```bash
  aws configure
  ```
- Docker installed

### 2) Create a repository on Docker Hub


### 3) Authenticate/Logon to  Docker 

### 4) Build the Docker image
From the repo root (or where your Dockerfile lives):
```bash
docker build -t potential-talent-hunt -f app/Dockerfile .
```

### 5) Tag the image for Docker Hub
```bash
docker tag potential-talent-hunt:latest \
  <userid>/potential-talent-hunt:latest
```

### 6) Push the image to Docker Hub
```bash
docker push <userid>/potential-talent-hunt:latest
```

### 7) Create an ECS Cluster
- In AWS Console â†’ **ECS** â†’ **Clusters** â†’ Create
- Choose **Fargate** (recommended for simplicity)

### 8) Create a Task Definition
- Container image: your Docker Hub image URI
- Port mapping: `8000` (FastAPI)
- CPU/Memory: choose based on FAISS/model size
- Environment variables: (optional) `MODEL_PATH`, `INDEX_PATH`, etc.

### 9) Create a Service
- Launch type: **Fargate**
- Desired tasks: 1+ (scale as needed)
- Networking: select VPC/subnets, enable public IP if required
- Load balancing: optional but recommended for production

### 10) Verify
- Open the service endpoint
- Confirm:
  - `/health` returns OK
  - `/docs` loads Swagger UI
  - `/search_jds` and `/star_rank` respond

---


## ğŸ™Œ Acknowledgements

Built as part of engagement at APZIVA as an applied AI & MLOps exploration project , demonstrating how to productionize semantic search systems end to end.

Please feel free to reach out to me over linkedin for any questions/discussions with regards to this project. 

