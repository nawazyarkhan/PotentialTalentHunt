{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b9d53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\my-pc\\miniconda3\\envs\\tf_env_new\\lib\\site-packages (from gensim) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\my-pc\\miniconda3\\envs\\tf_env_new\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\my-pc\\miniconda3\\envs\\tf_env_new\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Downloading gensim-4.4.0-cp312-cp312-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/24.4 MB 7.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 8.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.5/24.4 MB 8.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.6/24.4 MB 8.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.9/24.4 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.0/24.4 MB 8.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 12.8/24.4 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.7/24.4 MB 8.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.4 MB 8.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.4 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.2/24.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.3/24.4 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 7.7 MB/s  0:00:03\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: smart_open, gensim\n",
      "\n",
      "   ---------------------------------------- 0/2 [smart_open]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   -------------------- ------------------- 1/2 [gensim]\n",
      "   ---------------------------------------- 2/2 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.4.0 smart_open-7.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97bb1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python (from versions: none)\n",
      "ERROR: No matching distribution found for python\n"
     ]
    }
   ],
   "source": [
    "pip install python levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f2c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0f3214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"../Cell_Phones_and_Accessories_5.json\"\n",
    "if os.path.exists(file_path):\n",
    "\tdf = pd.read_json(file_path, lines=True)\n",
    "else:\n",
    "\tprint(f\"File '{file_path}' does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffefaa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe95e62",
   "metadata": {},
   "source": [
    "## want to create word2vec for reviews column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8481c566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## want to create word2vec model from reviewText column\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "157cc36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab06237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reviewText[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a46e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### preprocessing the text data for word2vec model training\n",
    "### genim is actually tokenizing the text data. It removed puncutation marks, converted to lower case \n",
    "### also, removed the stop words\n",
    "gensim.utils.simple_preprocess(df.reviewText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1222bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, look, good, and, stick, good, just, don...\n",
       "1    [these, stickers, work, like, the, review, say...\n",
       "2    [these, are, awesome, and, make, my, phone, lo...\n",
       "3    [item, arrived, in, great, time, and, was, in,...\n",
       "4    [awesome, stays, on, and, looks, great, can, b...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "review_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee44e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec( window = 10, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f66771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### see gensim documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f968b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4de60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a9a7d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 83868975)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97f5559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df50ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shabby', 0.6744567155838013),\n",
       " ('terrible', 0.6582924127578735),\n",
       " ('horrible', 0.607365071773529),\n",
       " ('lame', 0.5878769159317017),\n",
       " ('good', 0.5832192301750183),\n",
       " ('funny', 0.5473378300666809),\n",
       " ('okay', 0.5450829267501831),\n",
       " ('awful', 0.5391846299171448),\n",
       " ('poor', 0.5278714895248413),\n",
       " ('disappointing', 0.5248850584030151)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11f2ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.51995844)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "418f29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.79491526)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"good\", w2=\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af552ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c00d2ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"../data/potential-talents - Aspiring human resources - seeking human resources.csv\"\n",
    "if os.path.exists(file_path):\n",
    "\tdf_pt = pd.read_csv(file_path)\n",
    "else:\n",
    "\tprint(f\"File '{file_path}' does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a5e636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  fit  \n",
       "0                       Houston, Texas         85  NaN  \n",
       "1                               Kanada      500+   NaN  \n",
       "2  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                        Denton, Texas      500+   NaN  \n",
       "4                       İzmir, Türkiye      500+   NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6228e688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt['job_title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e699ea91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [bauer, college, of, business, graduate, magna...\n",
       "1    [native, english, teacher, at, epik, english, ...\n",
       "2           [aspiring, human, resources, professional]\n",
       "3         [people, development, coordinator, at, ryan]\n",
       "4    [advisory, board, member, at, celal, bayar, un...\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = df_pt['job_title'].apply(gensim.utils.simple_preprocess)\n",
    "job_title[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00916172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3775)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(job_title, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5b58e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec( window = 10, min_count=2, workers=4)\n",
    "model.build_vocab(job_title, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7798e289",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgensim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimple_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_title\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\utils.py:310\u001b[39m, in \u001b[36msimple_preprocess\u001b[39m\u001b[34m(doc, deacc, min_len, max_len)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimple_preprocess\u001b[39m(doc, deacc=\u001b[38;5;28;01mFalse\u001b[39;00m, min_len=\u001b[32m2\u001b[39m, max_len=\u001b[32m15\u001b[39m):\n\u001b[32m    288\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[32m    289\u001b[39m \n\u001b[32m    290\u001b[39m \u001b[33;03m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m \n\u001b[32m    308\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    309\u001b[39m     tokens = [\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeacc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeacc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m min_len <= \u001b[38;5;28mlen\u001b[39m(token) <= max_len \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token.startswith(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    312\u001b[39m     ]\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\utils.py:261\u001b[39m, in \u001b[36mtokenize\u001b[39m\u001b[34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Iteratively yield tokens as unicode strings, optionally removing accent marks and lowercasing it.\u001b[39;00m\n\u001b[32m    228\u001b[39m \n\u001b[32m    229\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m lowercase = lowercase \u001b[38;5;129;01mor\u001b[39;00m to_lower \u001b[38;5;129;01mor\u001b[39;00m lower\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m text = \u001b[43mto_unicode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lowercase:\n\u001b[32m    263\u001b[39m     text = text.lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\utils.py:364\u001b[39m, in \u001b[36many2unicode\u001b[39m\u001b[34m(text, encoding, errors)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: decoding to str: need a bytes-like object, list found"
     ]
    }
   ],
   "source": [
    "gensim.utils.simple_preprocess(job_title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a600e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6781, 29450)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df_pt['job_title'], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81dfe7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2019 C.T. Bauer College of Business Graduate (...\n",
       "1    Native English Teacher at EPIK (English Progra...\n",
       "2                Aspiring Human Resources Professional\n",
       "3               People Development Coordinator at Ryan\n",
       "4      Advisory Board Member at Celal Bayar University\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt['job_title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a04433df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddd3cc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 29450)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(df_pt['job_title'], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a931f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-potential-talents.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec782c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 86 is out of bounds for axis 0 with size 73",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_per\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\models\\word2vec.py:495\u001b[39m, in \u001b[36mWord2Vec.build_vocab\u001b[39m\u001b[34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28mself\u001b[39m.corpus_count = corpus_count\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m.corpus_total_words = total_words\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m report_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_raw_vocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_raw_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m report_values[\u001b[33m'\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.estimate_memory(vocab_size=report_values[\u001b[33m'\u001b[39m\u001b[33mnum_retained_words\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    497\u001b[39m \u001b[38;5;28mself\u001b[39m.prepare_weights(update=update)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\models\\word2vec.py:769\u001b[39m, in \u001b[36mWord2Vec.prepare_vocab\u001b[39m\u001b[34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[39m\n\u001b[32m    766\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_null_word()\n\u001b[32m    768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sorted_vocab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m update:\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_by_descending_frequency\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hs:\n\u001b[32m    772\u001b[39m     \u001b[38;5;66;03m# add info about each word's Huffman encoding\u001b[39;00m\n\u001b[32m    773\u001b[39m     \u001b[38;5;28mself\u001b[39m.create_binary_tree()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\My-PC\\miniconda3\\envs\\tf_env_new\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:759\u001b[39m, in \u001b[36mKeyedVectors.sort_by_descending_frequency\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vectors):\n\u001b[32m    758\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33msorting after vectors have been allocated is expensive & error-prone\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     \u001b[38;5;28mself\u001b[39m.vectors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount_sorted_indexes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;28mself\u001b[39m.key_to_index = {word: i \u001b[38;5;28;01mfor\u001b[39;00m i, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.index_to_key)}\n",
      "\u001b[31mIndexError\u001b[39m: index 86 is out of bounds for axis 0 with size 73"
     ]
    }
   ],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "537d8014",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'find_similar_words'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_similar_words\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mmanager\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Word2Vec' object has no attribute 'find_similar_words'"
     ]
    }
   ],
   "source": [
    "model.find_similar_words(\"manager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e442bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f35f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
